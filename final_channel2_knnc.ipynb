{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26083ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import glob\n",
    "from scipy.io import loadmat\n",
    "import scipy.io as sio\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import tree\n",
    "#import graphviz\n",
    "#from sklearn import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import model_evaluation_utils as meu\n",
    "#rom graphviz import Source\n",
    "#from io import StringIO\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "#mport pydotplus\n",
    "from sklearn import tree \n",
    "from IPython.display import Image\n",
    "#from skater.core.explanations import Interpretation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from pyrcn.datasets import load_digits\n",
    "#from pyrcn.echo_state_network import ESNClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "668d127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surpress warnings:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc90f85",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.12 GiB for an array with shape (5, 30000000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m IS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIS_3\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m IS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIS_4\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 13\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mDnI\u001b[49m\u001b[43m,\u001b[49m\u001b[43mIS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIS_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mDS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDS_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mIDS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIDS_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDnI_3\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatus\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDnI_4\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResult\u001b[39m\u001b[38;5;124m'\u001b[39m},inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m df\u001b[38;5;241m=\u001b[39mdf[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDnI_2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDS_2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIS_2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIDS_2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatus\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResult\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5447\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[1;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[0;32m   5444\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[0;32m   5446\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39msample(obj_len, size, replace, weights, rs)\n\u001b[1;32m-> 5447\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampled_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n\u001b[0;32m   5450\u001b[0m     result\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(result))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3701\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3692\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   3693\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_copy is deprecated and will be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3694\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m always returns a copy, so there is no need to specify this.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3695\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m   3696\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   3697\u001b[0m     )\n\u001b[0;32m   3699\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_take((), kwargs)\n\u001b[1;32m-> 3701\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3703\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mtake(\n\u001b[0;32m   3704\u001b[0m     indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis), verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3705\u001b[0m )\n\u001b[0;32m   3706\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5653\u001b[0m, in \u001b[0;36mNDFrame._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5650\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m():\n\u001b[0;32m   5651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mconsolidate()\n\u001b[1;32m-> 5653\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_protect_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5641\u001b[0m, in \u001b[0;36mNDFrame._protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   5639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f()\n\u001b[0;32m   5640\u001b[0m blocks_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[1;32m-> 5641\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mblocks) \u001b[38;5;241m!=\u001b[39m blocks_before:\n\u001b[0;32m   5643\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5651\u001b[0m, in \u001b[0;36mNDFrame._consolidate_inplace.<locals>.f\u001b[1;34m()\u001b[0m\n\u001b[0;32m   5650\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m():\n\u001b[1;32m-> 5651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:631\u001b[0m, in \u001b[0;36mBaseBlockManager.consolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    629\u001b[0m bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes, verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    630\u001b[0m bm\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m \u001b[43mbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bm\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1685\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1683\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1684\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1686\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2084\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2082\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2083\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2084\u001b[0m     merged_blocks \u001b[38;5;241m=\u001b[39m \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2085\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[0;32m   2086\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2087\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2088\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_blocks\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2118\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2115\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m bvals2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_concat_same_type(bvals2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2117\u001b[0m argsort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(new_mgr_locs)\n\u001b[1;32m-> 2118\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43margsort\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2119\u001b[0m new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m   2121\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(new_mgr_locs)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.12 GiB for an array with shape (5, 30000000) and data type float64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import data\n",
    "DnI=data.DnI\n",
    "IS=data.IS\n",
    "DS=data.DS\n",
    "IDS=data.IDS\n",
    "del DS['DS_3']\n",
    "del DS['DS_4']\n",
    "del IDS['IDS_3']\n",
    "del IDS['IDS_4']\n",
    "del IS['IS_3']\n",
    "del IS['IS_4']\n",
    "df=pd.concat([DnI,IS['IS_2'],DS['DS_2'],IDS['IDS_2']],axis=1).sample(frac=0.1)\n",
    "df.rename(columns={'DnI_3':'Status','DnI_4':'Result'},inplace=True)\n",
    "df=df[['DnI_2','DS_2','IS_2','IDS_2','Status','Result']]\n",
    "#outdata=df.to_dict('list')\n",
    "#sio.savemat('final.mat',outdata)\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['Status'])\n",
    "df[\"Category\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3ecffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X = df[['DnI_2','IS_2','IDS_2','DS_2']].copy()\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "y = df['Result'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.2)\n",
    "st_x= StandardScaler()    \n",
    "x_train= st_x.fit_transform(X_train)    \n",
    "x_test= st_x.transform(X_test)\n",
    "error_rate = []\n",
    "for i in range(1,40):\n",
    " knn = KNeighborsClassifier(n_neighbors=i)\n",
    " knn.fit(x_train,y_train)\n",
    " pred_i = knn.predict(x_test)\n",
    " error_rate.append(np.mean(pred_i != y_test))\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed',marker='o',markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n",
    "req_k_value = error_rate.index(min(error_rate))+1\n",
    "print(\"Minimum error:-\",min(error_rate),\"at K =\",req_k_value)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier= KNeighborsClassifier(n_neighbors=req_k_value, metric='minkowski', p=2 )  \n",
    "classifier.fit(x_train, y_train) \n",
    "y_pred= classifier.predict(x_test)\n",
    "#Creating the Confusion matrix  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "print(\"KNN - 10 neighbors Accuracy score and Confusion matrix\")\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "print(\"-------------------------\")\n",
    "metrics.plot_confusion_matrix(classifier, x_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f197ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X = df[['DnI_2','IS_2','IDS_2','DS_2']].copy()\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "y = df['Category'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.2)\n",
    "st_x= StandardScaler()    \n",
    "x_train= st_x.fit_transform(X_train)    \n",
    "x_test= st_x.transform(X_test)\n",
    "error_rate = []\n",
    "for i in range(1,40):\n",
    " knn = KNeighborsClassifier(n_neighbors=i)\n",
    " knn.fit(x_train,y_train)\n",
    " pred_i = knn.predict(x_test)\n",
    " error_rate.append(np.mean(pred_i != y_test))\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed',marker='o',markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n",
    "req_k_value = error_rate.index(min(error_rate))+1\n",
    "print(\"Minimum error:-\",min(error_rate),\"at K =\",req_k_value)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier= KNeighborsClassifier(n_neighbors=req_k_value, metric='minkowski', p=2 )  \n",
    "classifier.fit(x_train, y_train) \n",
    "y_pred= classifier.predict(x_test)\n",
    "#Creating the Confusion matrix  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "print(\"KNN - 10 neighbors Accuracy score and Confusion matrix\")\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "print(\"-------------------------\")\n",
    "metrics.plot_confusion_matrix(classifier, x_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838d102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X = df[['DnI_2']].copy()\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "y = df['Result'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.2)\n",
    "st_x= StandardScaler()    \n",
    "x_train= st_x.fit_transform(X_train)    \n",
    "x_test= st_x.transform(X_test)\n",
    "error_rate = []\n",
    "for i in range(1,40):\n",
    " knn = KNeighborsClassifier(n_neighbors=i)\n",
    " knn.fit(x_train,y_train)\n",
    " pred_i = knn.predict(x_test)\n",
    " error_rate.append(np.mean(pred_i != y_test))\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed',marker='o',markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n",
    "req_k_value = error_rate.index(min(error_rate))+1\n",
    "print(\"Minimum error:-\",min(error_rate),\"at K =\",req_k_value)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier= KNeighborsClassifier(n_neighbors=req_k_value, metric='minkowski', p=2 )  \n",
    "classifier.fit(x_train, y_train) \n",
    "y_pred= classifier.predict(x_test)\n",
    "#Creating the Confusion matrix  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "print(\"KNN - 10 neighbors Accuracy score and Confusion matrix\")\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "print(\"-------------------------\")\n",
    "metricss.plot_confusion_matrix(classifier, x_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630685b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X = df[['DnI_2']].copy()\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "y = df['Category'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.2)\n",
    "st_x= StandardScaler()    \n",
    "x_train= st_x.fit_transform(X_train)    \n",
    "x_test= st_x.transform(X_test)\n",
    "error_rate = []\n",
    "for i in range(1,40):\n",
    " knn = KNeighborsClassifier(n_neighbors=i)\n",
    " knn.fit(x_train,y_train)\n",
    " pred_i = knn.predict(x_test)\n",
    " error_rate.append(np.mean(pred_i != y_test))\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed',marker='o',markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n",
    "req_k_value = error_rate.index(min(error_rate))+1\n",
    "print(\"Minimum error:-\",min(error_rate),\"at K =\",req_k_value)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier= KNeighborsClassifier(n_neighbors=req_k_value, metric='minkowski', p=2 )  \n",
    "classifier.fit(x_train, y_train) \n",
    "y_pred= classifier.predict(x_test)\n",
    "#Creating the Confusion matrix  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "print(\"KNN - 10 neighbors Accuracy score and Confusion matrix\")\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "print(\"-------------------------\")\n",
    "metrics.plot_confusion_matrix(classifier, x_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f74f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('k=2')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#X = df[['DnI_2','IDS_2','DS_2','IS_2']].copy()\n",
    "#X = df[['DnI_2','IS_2','IDS_2','DS_2']].copy()\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "y = df['Result'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.2)\n",
    "\n",
    "k = 2\n",
    "#Train Model and Predict  \n",
    "neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
    "print(neigh)\n",
    "test_predictions=neigh.predict(X_test)\n",
    "meu.get_metrics(true_labels=y_test, predicted_labels=test_predictions)\n",
    "print(\"KNeighboursClassifier's Accuracy: \", metrics.accuracy_score(y_test, test_predictions))\n",
    "print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\n",
    "print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, test_predictions))\n",
    "scores = cross_val_score(neigh, X_test, y_test, cv=10)\n",
    "print(\"Score:\", np.mean(scores),\"\\n\")\n",
    "metrics.plot_confusion_matrix(neigh,X_test,y_test)\n",
    "plt.show()\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ffc36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#X = df[['DnI_2','IDS_2','DS_2','IS_2']].copy()\n",
    "X = df[['DnI_2','IS_2','IDS_2','DS_2']].copy()\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "y = df['Category'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.2)\n",
    "\n",
    "\n",
    "#Train Model and Predict  \n",
    "neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
    "print(neigh)\n",
    "test_predictions=neigh.predict(X_test)\n",
    "meu.get_metrics(true_labels=y_test, predicted_labels=test_predictions)\n",
    "print(\"KNeighboursClassifier's Accuracy: \", metrics.accuracy_score(y_test, test_predictions))\n",
    "print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\n",
    "print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, test_predictions))\n",
    "scores = cross_val_score(neigh, X_test, y_test, cv=10)\n",
    "print(\"Score:\", np.mean(scores),\"\\n\")\n",
    "metrics.plot_confusion_matrix(neigh,X_test,y_test)\n",
    "plt.show()\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ec9336",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#X = df[['DnI_2','IDS_2','DS_2','IS_2']].copy()\n",
    "X = df[['DnI_2']].copy()\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "y = df['Result'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.2)\n",
    "\n",
    "\n",
    "#Train Model and Predict  \n",
    "neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
    "print(neigh)\n",
    "test_predictions=neigh.predict(X_test)\n",
    "meu.get_metrics(true_labels=y_test, predicted_labels=test_predictions)\n",
    "print(\"KNeighboursClassifier's Accuracy: \", metrics.accuracy_score(y_test, test_predictions))\n",
    "print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\n",
    "print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, test_predictions))\n",
    "scores = cross_val_score(neigh, X_test, y_test, cv=10)\n",
    "print(\"Score:\", np.mean(scores),\"\\n\")\n",
    "metrics.plot_confusion_matrix(neigh,X_test,y_test)\n",
    "plt.show()\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f7f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#X = df[['DnI_2','IDS_2','DS_2','IS_2']].copy()\n",
    "X = df[['DnI_2']].copy()\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "y = df['Category'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.2)\n",
    "\n",
    "\n",
    "#Train Model and Predict  \n",
    "neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
    "print(neigh)\n",
    "test_predictions=neigh.predict(X_test)\n",
    "meu.get_metrics(true_labels=y_test, predicted_labels=test_predictions)\n",
    "print(\"KNeighboursClassifier's Accuracy: \", metrics.accuracy_score(y_test, test_predictions))\n",
    "print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\n",
    "print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, test_predictions))\n",
    "scores = cross_val_score(neigh, X_test, y_test, cv=10)\n",
    "print(\"Score:\", np.mean(scores),\"\\n\")\n",
    "metrics.plot_confusion_matrix(neigh,X_test,y_test)\n",
    "plt.show()\n",
    "del X\n",
    "del y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
