{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99f8b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import glob\n",
    "from scipy.io import loadmat\n",
    "import scipy.io as sio\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "#from sklearn import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import model_evaluation_utils as meu\n",
    "#from graphviz import Source\n",
    "#import graphviz\n",
    "from io import StringIO\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "#import pydotplus\n",
    "from sklearn import tree \n",
    "from IPython.display import Image\n",
    "#from skater.core.explanations import Interpretation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from pyrcn.datasets import load_digits\n",
    "#from pyrcn.echo_state_network import ESNClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "356d54bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surpress warnings:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c45344d",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 458. MiB for an array with shape (30000000,) and data type complex128",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[0;32m      3\u001b[0m DnI\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mDnI\n\u001b[0;32m      4\u001b[0m IS\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mIS\n",
      "File \u001b[1;32m~\\Downloads\\v43hmbwxpm-2-20221124T024842Z-001\\v43hmbwxpm-2\\output\\data.py:1267\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m   1265\u001b[0m df_list\u001b[38;5;241m=\u001b[39m[df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15]\n\u001b[0;32m   1266\u001b[0m DS\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mconcat(df_list)\n\u001b[1;32m-> 1267\u001b[0m con_list\u001b[38;5;241m=\u001b[39m[\u001b[43mDS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStatus\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHealthy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,DS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatus\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFaulty\u001b[39m\u001b[38;5;124m\"\u001b[39m,na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[0;32m   1268\u001b[0m val_list\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1269\u001b[0m DS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResult\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mselect(con_list,val_list)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:125\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use .str.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with values of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred dtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m     )\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:1222\u001b[0m, in \u001b[0;36mStringMethods.contains\u001b[1;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m regex \u001b[38;5;129;01mand\u001b[39;00m re\u001b[38;5;241m.\u001b[39mcompile(pat)\u001b[38;5;241m.\u001b[39mgroups:\n\u001b[0;32m   1215\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis pattern is interpreted as a regular expression, and has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch groups. To actually get the groups, use str.extract.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1218\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1219\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1220\u001b[0m     )\n\u001b[1;32m-> 1222\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str_contains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_result(result, fill_value\u001b[38;5;241m=\u001b[39mna, returns_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\strings\\object_array.py:131\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_contains\u001b[1;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[0;32m    129\u001b[0m         upper_pat \u001b[38;5;241m=\u001b[39m pat\u001b[38;5;241m.\u001b[39mupper()\n\u001b[0;32m    130\u001b[0m         f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: upper_pat \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mupper()\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbool\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\strings\\object_array.py:71\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_map\u001b[1;34m(self, f, na_value, dtype, convert)\u001b[0m\n\u001b[0;32m     69\u001b[0m map_convert \u001b[38;5;241m=\u001b[39m convert \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(mask)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 71\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_convert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;66;03m# Reraise the exception if callable `f` got wrong number of args.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# The user may want to be warned by this, instead of getting NaN\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     p_err \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m((takes)|(missing)) (?(2)from \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ to )?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(?(3)required )positional arguments?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     78\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2831\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2457\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 458. MiB for an array with shape (30000000,) and data type complex128"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import data\n",
    "DnI=data.DnI\n",
    "IS=data.IS\n",
    "DS=data.DS\n",
    "IDS=data.IDS\n",
    "del DS['DS_3']\n",
    "del DS['DS_4']\n",
    "del IDS['IDS_3']\n",
    "del IDS['IDS_4']\n",
    "del IS['IS_3']\n",
    "del IS['IS_4']\n",
    "df=pd.concat([DnI,IS['IS_1'],DS['DS_1'],IDS['IDS_1']],axis=1).sample(frac=0.1)\n",
    "df.rename(columns={'DnI_3':'Status','DnI_4':'Result'},inplace=True)\n",
    "df=df[['DnI_1','DS_1','IS_1','IDS_1','Status','Result']]\n",
    "#outdata=df.to_dict('list')\n",
    "#sio.savemat('final.mat',outdata)\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['Status'])\n",
    "df[\"Category\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654f1eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "print('Columns for test data is Increasing Speed , Decreasing Speed,Decreasing then Increasing & increasing then decreasing condition' )\n",
    "#df=df.sample(frac=0.10)\n",
    "#X = df[['DnI_2','IS_2','IDS_2','DS_2']].copy()\n",
    "X = df[['DnI_2','IS_2','IDS_2','DS_2']].copy()\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "y = df['Category'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.2)\n",
    "\n",
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
    "clf.predict_proba(X_test[:1])\n",
    "\n",
    "clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "metrics.plot_confusion_matrix(clf,X_test,y_test)\n",
    "test_predictions=clf.predict(X_test)\n",
    "print(test_predictions)\n",
    "print(clf)\n",
    "\n",
    "#print(y_test)\n",
    "print(y_test.shape,test_predictions.shape)\n",
    "meu.get_metrics(true_labels=y_test,predicted_labels=test_predictions)\n",
    "#accuracy_score(y_test,test_predictions)\n",
    "cm=sklearn.metrics.confusion_matrix(y_test,test_predictions)\n",
    "#meu.display_confusion_matrix(y_test,test_predictions)\n",
    "meu.display_classification_report(true_labels=y_test, predicted_labels=test_predictions,\n",
    "                                  classes=df.Category.unique())\n",
    "#print(y_test)\n",
    "\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b6d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "print('Columns for test data is Increasing Speed , Decreasing Speed,Decreasing then Increasing & increasing then decreasing condition' )\n",
    "#df=df.sample(frac=0.10)\n",
    "X = df[['DnI_2','IS_2','IDS_2','DS_2']].copy()\n",
    "#X = df[['DnI_1','IS_1','IDS_1','DS_1']].copy()\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "y = df['Category'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.2)\n",
    "\n",
    "clf = MLPClassifier(random_state=1, max_iter=600).fit(X_train, y_train)\n",
    "clf.predict_proba(X_test[:1])\n",
    "\n",
    "clf.predict(X_test)\n",
    "\n",
    "\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "print(clf.score(X_test,y_test))\n",
    "metrics.plot_confusion_matrix(clf,X_test,y_test)\n",
    "\n",
    "#print(y_test)\n",
    "test_predictions=clf.predict(X_test)\n",
    "print(test_predictions)\n",
    "print(clf)\n",
    "\n",
    "#print(y_test)\n",
    "print(y_test.shape,test_predictions.shape)\n",
    "meu.get_metrics(true_labels=y_test,predicted_labels=test_predictions)\n",
    "#accuracy_score(y_test,test_predictions)\n",
    "cm=sklearn.metrics.confusion_matrix(y_test,test_predictions)\n",
    "#meu.display_confusion_matrix(y_test,test_predictions)\n",
    "meu.display_classification_report(true_labels=y_test, predicted_labels=test_predictions,\n",
    "                                  classes=df.Category.unique())\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a574745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "print('Columns for test data is Increasing Speed , Decreasing Speed,Decreasing then Increasing & increasing then decreasing condition' )\n",
    "#df=df.sample(frac=0.10)\n",
    "X = df[['DnI_2','IS_2','IDS_2','DS_2']].copy()\n",
    "#X = df[['DnI_1','IS_1','IDS_1','DS_1']].copy()\n",
    "X=np.float64(X)\n",
    "print('hi')\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "y = df['Result'].copy()\n",
    "y=np.float64(y)\n",
    "print('z')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.2)\n",
    "\n",
    "clf = MLPClassifier(random_state=1, max_iter=600).fit(X_train, y_train)\n",
    "clf.predict_proba(X_test[:1])\n",
    "\n",
    "clf.predict(X_test)\n",
    "\n",
    "\n",
    "l=clf.score(X_test, y_test)\n",
    "print(l)\n",
    "\n",
    "metrics.plot_confusion_matrix(clf,X_test,y_test)\n",
    "test_predictions=clf.predict(X_test)\n",
    "print(test_predictions)\n",
    "print(clf)\n",
    "\n",
    "#print(y_test)\n",
    "print(y_test.shape,test_predictions.shape)\n",
    "meu.get_metrics(true_labels=y_test,predicted_labels=test_predictions)\n",
    "#accuracy_score(y_test,test_predictions)\n",
    "cm=sklearn.metrics.confusion_matrix(y_test,test_predictions)\n",
    "#meu.display_confusion_matrix(y_test,test_predictions)\n",
    "meu.display_classification_report(true_labels=y_test, predicted_labels=test_predictions,\n",
    "                                  classes=df.Result.unique())\n",
    "#print(y_test)\n",
    "\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c2727",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "print('Columns for test data is Increasing Speed , ' )\n",
    "#df=df.sample(frac=0.10)\n",
    "X = df[['IS_2']].copy()\n",
    "#X = df[['DnI_2','IS_2','IDS_2','DS_2']].copy()\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "y = df['Result'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.2)\n",
    "\n",
    "clf = MLPClassifier(random_state=1, max_iter=600).fit(X_train, y_train)\n",
    "clf.predict_proba(X_test[:1])\n",
    "\n",
    "clf.predict(X_test)\n",
    "\n",
    "\n",
    "clf.score(X_test, y_test)\n",
    "print(clf.score(X_test,y_test))\n",
    "metrics.plot_confusion_matrix(clf,X_test,y_test)\n",
    "\n",
    "\n",
    "#print(y_test)\n",
    "test_predictions=clf.predict(X_test)\n",
    "print(test_predictions)\n",
    "print(clf)\n",
    "\n",
    "#print(y_test)\n",
    "print(y_test.shape,test_predictions.shape)\n",
    "meu.get_metrics(true_labels=y_test,predicted_labels=test_predictions)\n",
    "#accuracy_score(y_test,test_predictions)\n",
    "cm=sklearn.metrics.confusion_matrix(y_test,test_predictions)\n",
    "#meu.display_confusion_matrix(y_test,test_predictions)\n",
    "meu.display_classification_report(true_labels=y_test, predicted_labels=test_predictions,\n",
    "                                  classes=df.Result.unique())\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370b037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "print('Columns for test data is Increasing Speed , ' )\n",
    "#df=df.sample(frac=0.10)\n",
    "X = df[['IS_2']].copy()\n",
    "#X = df[['DnI_2','IS_2','IDS_2','DS_2']].copy()\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "y = df['Category'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.2)\n",
    "\n",
    "clf = MLPClassifier(random_state=1, max_iter=600).fit(X_train, y_train)\n",
    "clf.predict_proba(X_test[:1])\n",
    "\n",
    "clf.predict(X_test)\n",
    "\n",
    "\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "print(clf.score(X_test,y_test))\n",
    "\n",
    "metrics.plot_confusion_matrix(clf,X_test,y_test)\n",
    "#print(y_test)\n",
    "test_predictions=clf.predict(X_test)\n",
    "print(test_predictions)\n",
    "print(clf)\n",
    "\n",
    "#print(y_test)\n",
    "print(y_test.shape,test_predictions.shape)\n",
    "meu.get_metrics(true_labels=y_test,predicted_labels=test_predictions)\n",
    "#accuracy_score(y_test,test_predictions)\n",
    "cm=sklearn.metrics.confusion_matrix(y_test,test_predictions)\n",
    "#meu.display_confusion_matrix(y_test,test_predictions)\n",
    "meu.display_classification_report(true_labels=y_test, predicted_labels=test_predictions,\n",
    "                                  classes=df.Category.unique())\n",
    "del X\n",
    "del y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
